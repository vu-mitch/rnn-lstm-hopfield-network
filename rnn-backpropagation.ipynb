{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43ea3c26",
   "metadata": {},
   "source": [
    "# Assignment 2: Training the Fully Recurrent Network\n",
    "\n",
    "*Author:* Thomas Adler\n",
    "\n",
    "*Copyright statement:* This  material,  no  matter  whether  in  printed  or  electronic  form,  may  be  used  for  personal  and non-commercial educational use only.  Any reproduction of this manuscript, no matter whether as a whole or in parts, no matter whether in printed or in electronic form, requires explicit prior acceptance of the authors.\n",
    "\n",
    "\n",
    "## Exercise 1: Data generation\n",
    "\n",
    "There are two classes, both occurring with probability 0.5. There is one input unit. Only the first sequence element conveys relevant information about the class. Sequence elements at positions $t > 1$ stem from a Gaussian with mean zero and variance 0.2. The first sequence element is 1.0 (-1.0) for class 1 (2). Target at sequence end is 1.0 (0.0) for class 1 (2)\n",
    "\n",
    "Write a function `generate_data` that takes an integer `T` as argument which represents the sequence length. Seed the `numpy` random generator with the number `0xDEADBEEF`. Implement the [Python3 generator](https://docs.python.org/3/glossary.html#term-generator) pattern and produce data in the way described above. The input sequences should have the shape `(T, 1)` and the target values should have the shape `(1,)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "04244bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.special import expit as sigmoid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class FullyRecurrentNetwork(object):\n",
    "    def __init__(self, D, I, K):\n",
    "        self.W = np.random.uniform(-0.01, 0.01, (I, D))\n",
    "        self.R = np.random.uniform(-0.01, 0.01, (I, I))\n",
    "        self.V = np.random.uniform(-0.01, 0.01, (K, I))\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        # helper function for numerically stable loss\n",
    "        def f(z):\n",
    "            return np.log1p(np.exp(-np.absolute(z))) + np.maximum(0, z)\n",
    "        \n",
    "        # infer dims\n",
    "        T, D = x.shape\n",
    "        K, I = self.V.shape\n",
    "\n",
    "        # init result arrays\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.a = np.zeros((T, I))\n",
    "        self.s = np.zeros((T, I))\n",
    "\n",
    "        # iterate forward in time \n",
    "        # trick: access model.a[-1] in first iteration\n",
    "        for t in range(T):\n",
    "            self.s[t] = self.W @ x[t] + self.R @ self.a[t-1]\n",
    "            self.a[t] = np.tanh(self.s[t])\n",
    "            \n",
    "        self.z = self.V @ self.a[t]\n",
    "        loss = y * f(-self.z) + (1-y) * f(self.z)\n",
    "        return loss\n",
    "\n",
    "T, D, I, K = 10, 3, 5, 1\n",
    "model = FullyRecurrentNetwork(D, I, K)\n",
    "model.forward(np.random.uniform(-1, 1, (T, D)), 1)\n",
    "\n",
    "def generate_data(T, seed=0xDEADBEEF):\n",
    "    np.random.seed(seed)\n",
    "    while True:\n",
    "        class_elem = np.random.binomial(1, p=0.5, size=(1,))\n",
    "        x = np.random.normal(0, np.sqrt(0.2), size=(T,1))\n",
    "        x[0] = class_elem\n",
    "        yield x, np.array([1.]) if class_elem == 1. else np.array([0.])\n",
    "\n",
    "data = generate_data(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9826f26",
   "metadata": {},
   "source": [
    "## Exercise 2: Gradients for the network parameters\n",
    "Compute gradients of the total loss \n",
    "$$\n",
    "L = \\sum_{t=1}^T L(t), \\quad \\text{where} \\quad L(t) = L(z(t), y(t))\n",
    "$$\n",
    "w.r.t. the weights of the fully recurrent network. To this end, find the derivative of the loss w.r.t. the logits and hidden pre-activations first, i.e., \n",
    "$$\n",
    "\\psi^\\top(t) = \\frac{\\partial L}{\\partial z(t)} \\quad \\text{and} \\quad \\delta^\\top(t) = \\frac{\\partial L}{\\partial s(t)}.\n",
    "$$\n",
    "With the help of these intermediate results you should be able to compute the gradients w.r.t. the weights, i.e., $\\nabla_W L, \\nabla_R L, \\nabla_V L$. \n",
    "\n",
    "*Hint: Take a look at the computational graph from the previous assignment to see the functional dependencies.*\n",
    "\n",
    "*Remark: Although we only have one label at the end of the sequence, we consider the more general case of evaluating a loss at every time step in this exercise (many-to-many mapping).*\n",
    "\n",
    "########## YOUR SOLUTION HERE ##########\n",
    "\n",
    "+ 1) From Ass 1 we know the derivative of the loss:\n",
    "$$\\frac{\\partial}{\\partial z(t)} L(z(t),y(t))=\\frac{1}{1+e^{-z(t)}}-y(t)$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial z(t)} L&= \\frac{\\partial}{\\partial z(t)}\\sum\\limits_{\\tau=1}^{T}L(z(\\tau),y(\\tau))\\\\\n",
    "&= \\frac{\\partial}{\\partial z(t)}L(z(t),y(t))\\\\\n",
    "&= \\sigma(z(t))-y(t) = \\psi(t)^{\\top}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "+ 2) Similar to 2.12\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\delta^{\\top}(t) &=  \\frac{\\partial L}{\\partial s(t)}\\\\\n",
    "&= \\frac{\\partial L}{\\partial a(t)}\\frac{\\partial a(t)}{\\partial s(t)}\\\\\n",
    "&= \\left(\\frac{\\partial L(y(t),z(t))}{\\partial a(t)}+\\frac{\\partial L}{\\partial s(t+1)}\\frac{\\partial s(t+1)}{\\partial a(t)}\\right)\\frac{\\partial a(t)}{\\partial s(t)}\\\\\n",
    "&= \\left(\\frac{\\partial L}{\\partial z(t)}\\frac{\\partial z(t)}{\\partial a(t)}+\\delta(t+1)^{\\top}R\\right)\\frac{\\partial a(t)}{\\partial s(t)}\\\\\n",
    "&= \\left(\\psi(t)^{\\top}V+\\delta(t+1)^{\\top}R\\right)f'(s(t))\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "+ 3) From 2.18, 2.19 and 2.20 we get the Outer Product Representation\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial V} &= \\sum\\limits_{t=1}^{T}\\psi(t)a(t)^\\top\\\\\n",
    "\\frac{\\partial L}{\\partial R}&= \\sum\\limits_{t=1}^{T}\\delta(t)a(t-1)^\\top\\\\\n",
    "\\frac{\\partial L}{\\partial W}&= \\sum\\limits_{t=1}^{T}\\delta(t)x(t)^\\top\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21968f2c",
   "metadata": {},
   "source": [
    "## Exercise 3: The backward pass\n",
    "Write a function `backward` that takes a model `self` as argument. The function should compute the gradients of the loss with respect to all model parameters and store them to `self.dW`, `self.dR`, `self.dV`, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "42e3d13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh_deriv(x):\n",
    "        return 1 - np.tanh(x)**2\n",
    "    \n",
    "def backward(self):\n",
    "    ########## YOUR SOLUTION HERE ##########\n",
    "    # Calculation of psi, Last element has a value for z\n",
    "    psi = np.zeros(((len(self.x),) + self.z.shape))\n",
    "    psi[-1] = sigmoid(self.z) - self.y\n",
    "    #print(sigmoid(self.z), self.y)\n",
    "    \n",
    "    # Calculation of delta. Setting last element first, as it's the only psi, and all others depend on the next one.\n",
    "    delta = np.ones(self.s.shape)\n",
    "    delta[-1] = np.dot(psi[-1], self.V) * tanh_deriv(self.s[-1])\n",
    "    T_idx = len(delta) - 1\n",
    "    #print(self.s[-1])\n",
    "    \n",
    "    self.dR = np.zeros_like(self.R)\n",
    "    self.dW = np.zeros_like(self.W)\n",
    "    self.dV = np.dot(psi[np.newaxis, -1], self.a[np.newaxis, -1])\n",
    "    \n",
    "    for t in range(1, len(delta)): \n",
    "        delta[T_idx-t] = (delta[T_idx-t+1] @ self.R) * tanh_deriv(self.s[-1])\n",
    "    \n",
    "    a_t = None\n",
    "    \n",
    "    for t in range(self.x.shape[0]):\n",
    "        # np.dot() doesn't work here\n",
    "        self.dW += delta[np.newaxis, t].T @ self.x[np.newaxis, t] \n",
    "\n",
    "        if t > 0:\n",
    "            a_t = self.a[np.newaxis, t-1]\n",
    "        else:\n",
    "            a_t = np.zeros((1,)+self.a.shape[1:])\n",
    "            \n",
    "        self.dR += delta[np.newaxis, t].T @ a_t\n",
    "\n",
    "\n",
    "FullyRecurrentNetwork.backward = backward\n",
    "model.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58181c6",
   "metadata": {},
   "source": [
    "## Exercise 4: Gradient checking\n",
    "Write a function `grad_check` that takes a model `self`, a float `eps` and another float `thresh` as arguments and computes the numerical gradients of the model parameters according to the approximation\n",
    "$$\n",
    "f'(x) \\approx \\frac{f(x + \\varepsilon) - f(x - \\varepsilon)}{2 \\varepsilon}.\n",
    "$$\n",
    "If any of the analytical gradients are farther than `thresh` away from the numerical gradients the function should throw an error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "227e8631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_check(self, eps, thresh):\n",
    "    ########## YOUR SOLUTION HERE ##########\n",
    "    param = (self.W, self.R, self.V)\n",
    "    grads = (self.dW, self.dR, self.dV)\n",
    "    \n",
    "    for p, g in zip(param, grads):\n",
    "        for i in range(p.shape[0]):\n",
    "            for j in range(p.shape[1]):\n",
    "                temp = p[i, j]\n",
    "                p[i,j] = temp + eps\n",
    "                loss0 = self.forward(self.x, 1)\n",
    "                loss1 = self.forward(self.x, 1)\n",
    "                p[i, j] = temp\n",
    "                grad = (loss0 - loss1) / (2*eps)\n",
    "                err = np.abs(grad - g[i,j])\n",
    "                assert(err<thresh)\n",
    "                \n",
    "FullyRecurrentNetwork.grad_check = grad_check\n",
    "model.grad_check(1e-7, 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5cdc05",
   "metadata": {},
   "source": [
    "## Exercise 5: Parameter update\n",
    "\n",
    "Write a function `update` that takes a model `self` and a float argument `eta`, which represents the learning rate. The method should implement the gradient descent update rule $\\theta \\gets \\theta - \\eta \\nabla_{\\theta}L$ for all model parameters $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e93c02c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(self, eta):\n",
    "    ########## YOUR SOLUTION HERE ##########\n",
    "    self.W -= eta * self.dW\n",
    "    self.R -= eta * self.dR\n",
    "    self.V -= eta * self.dV\n",
    "\n",
    "FullyRecurrentNetwork.update = update\n",
    "model.update(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19801bb8",
   "metadata": {},
   "source": [
    "## Exercise 6: Network training\n",
    "\n",
    "Train the fully recurrent network with 32 hidden units. Start with input sequences of length one and tune the learning rate and the number of update steps. Then increase the sequence length by one and tune the hyperparameters again. What is the maximal sequence length for which the fully recurrent network can achieve a performance that is better than random? Visualize your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6d9781ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## YOUR SOLUTION HERE ##########\n",
    "def train(max_updates=2000):\n",
    "    def softmax(z):\n",
    "        return np.log1p(np.exp(-np.absolute(z))) + np.maximum(0, z)\n",
    "    \n",
    "    sequence_length = 1\n",
    "    while True:\n",
    "        num_updates = 0\n",
    "        lr = 0.0001\n",
    "        model = FullyRecurrentNetwork(D=1, I=32, K=1)\n",
    "        losses, accuracies, lrs = list(), list(), list()\n",
    "        data = generate_data(sequence_length)\n",
    "        \n",
    "        while True:\n",
    "            x, y = next(data)\n",
    "\n",
    "            loss = model.forward(x, y)\n",
    "            losses.append(loss)\n",
    "                            \n",
    "            if num_updates % 500 == 0:\n",
    "                lr *= 10\n",
    "                \n",
    "            model.backward()\n",
    "            model.update(lr)\n",
    "            lrs.append(lr)\n",
    "            num_updates += 1\n",
    "            \n",
    "            # take loss < 0.3 as convergent\n",
    "            if loss < 0.3:\n",
    "                yield sequence_length, num_updates, losses, lrs\n",
    "                break\n",
    "\n",
    "            if num_updates >= max_updates:\n",
    "                return\n",
    "            \n",
    "        sequence_length += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e5c2088-e79b-422a-bb37-777de9c4a329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_generator = train()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16,4))\n",
    "\n",
    "axs[0].set_title(\"Losses\")\n",
    "axs[0].set_ylim(0,1)\n",
    "axs[0].set_xlabel(\"Update Step\")\n",
    "\n",
    "axs[1].set_title(\"Learning Rates\")\n",
    "axs[1].set_ylim(0,1)\n",
    "axs[1].set_xlabel(\"Update Step\")\n",
    "\n",
    "for sequence_length, num_updates, losses, lrs in training_generator:\n",
    "    axs[0].plot(losses, label=f\"Sequence Length {sequence_length}\")\n",
    "    axs[1].plot(lrs, label=f\"Sequence Length {sequence_length}\")\n",
    "\n",
    "axs[0].legend()\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b52057",
   "metadata": {},
   "source": [
    "## Exercise 7: The Vanishing Gradient Problem\n",
    "\n",
    "Analyze why the network is incapable of learning long-term dependencies. Show that $\\|\\frac{\\partial a(T)}{\\partial a(1)}\\|_2 \\leq \\|R\\|_2^{T-1}$ , where $\\|\\cdot\\|_2$ is the spectral norm, and discuss how that affects the propagation of error signals through the time dimension of the network. \n",
    "\n",
    "*Hint: Use the fact that the spectral norm is submultiplicative for square matrices, i.e. $\\|AB\\|_2 \\leq \\|A\\|_2\\|B\\|_2$ if $A$ and $B$ are both square.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158130a5",
   "metadata": {},
   "source": [
    "+ 1) We have that:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial a(t)}{\\partial a(t-1)}&= \\frac{\\partial f(W^{\\top}x(t)+R^{\\top}a(t-1))}{\\partial a(t-1)}R\\\\\n",
    "&= \\frac{\\partial f(Wx(t)+Ra(t-1))}{\\partial a(t-1)}R\\\\\n",
    "&= f'(Wx(t)+Ra(t-1))R\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "+ 2) By using chain rule:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial a(T)}{\\partial a(1)} &= \\frac{\\partial a(T)}{\\partial a(T-1)}\\frac{\\partial a(T-1)}{\\partial a(T-2)}\\ldots\\frac{\\partial a(2)}{\\partial a(1)}\\\\\n",
    "&= f'(Wx(T)+Ra(T-1))R\\cdot f'(Wx(T-1)+Ra(T-2))R \\ldots f'(Wx(2)+Ra(1))R\\\\\n",
    "&= R^{T-1}\\prod_{\\tau=0}^{T-1}f'(Wx(\\tau)+Ra(\\tau-1))\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "+ 3) First inequalitiy holds because $f'(x)\\leq 1$ and the second inequalitiy holds from the submultiplicative property of the spectral norm with the square matrix\n",
    "\n",
    "$$\\|\\frac{\\partial a(T)}{\\partial a(1)}\\|_{2}=\\quad \\|R^{T-1}\\prod_{\\tau=0}^{T-1}f'(Wx(\\tau)+Ra(\\tau-1))\\|_{2}\\quad \\leq \\quad \\|R^{T-1}\\|_{2}\\leq\\|R\\|^{T-1}_{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e50719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
